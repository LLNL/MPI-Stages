#!/usr/bin/env python2

# this daemon is in charge of communication between it and application instances
# and other head daemons in the job

import os
import sys
import copy
import tempfile
import subprocess
import signal
import socket
import re
import logging

#def prefix_sum(array):
#	out = []
#
#	for idx, item in enumerate(array):
#		if idx == 0:
#			out.append(item)
#		else:
#			out.append(item + out[idx-1])
#
#	return out

#def lookup_setup():
#	# uncompress task list
#	prefixes = []
#	for element in os.environ['SLURM_TASKS_PER_NODE'].split(','):
#		if '(' in element:
#			# 143(x27)
#			count, mult = element.split('(x')
#			
#			for idx in xrange(int(mult[:-1])):
#				prefixes.append(count)
#			
#		else:
#			prefixes.append(int(element))
#	
#	# generate prefix sum array
#	global task_count_offsets 
#	task_count_offsets = prefix_sum(prefixes)

#def lookup_rank(rank):
#	if os.environ['EXAMPI_ENV'] == 'local':
#		return 'localhost'
#
#	# local rank
#	if rank in local_global_ids:
#		return local_nodename
#
#	# global rank 
#	else:
#		for idx, bound in enumerate(task_count_offsets):
#			if bound <= rank:
#				return nodelist[idx]

class HeadDaemon:
	def __init__(self, daemon_port, mpi_base_port):
		logname = 'mpi_head_daemon_' + str(os.environ['EXAMPI_RANK']) + '.log'
		logging.basicConfig(filename=logname, level=logging.DEBUG)

		self.daemon_port = daemon_port
		self.shutdown = False

		# create socket
		self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
		
		self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, 0)
		self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 0)
		self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

		self.sock.bind((socket.gethostname(), daemon_port))
		logging.info('socket bound on ' + str(socket.gethostname()) + ' ' + str(socket.gethostbyname(socket.gethostname())) + ' ' + str(self.daemon_port))

		# create signal handler
		signal.signal(signal.SIGINT, self.signal_handler)
		logging.info('set up signal handler')
			
		# local data
		self.mpi_base_port = mpi_base_port
		self.rank_waiting_set = set()
		self.rank_done_set = set()
		self.local_rank_count = None
		self.local_ranks = []
		self.barrier_unannounced = True

		# global daemon
		self.root_node = None
		self.root_host = None
		self.node_waiting_set = set()
		self.global_node_count = None
		self.global_nodes = []

		self.prepare_lookup()

	def __del__(self):
		logging.info('shutting down socket')
		if self.sock is not None:
			self.sock.close()
		logging.info('shutting down')

	def signal_handler(self, signal, frame):
		logging.warning("HEAD DAEMON signal received " + str(signal))
		self.shutdown = True

		self.sock.close()
		self.sock = None

	def prepare_lookup(self):
		if os.environ['EXAMPI_ENV'] == 'local':
			self.local_rank_count = int(os.environ['EXAMPI_WORLD_SIZE'])
			self.local_ranks = range(int(os.environ['EXAMPI_WORLD_SIZE']))

			self.global_node_count = 1
			self.global_nodes = [socket.gethostname()]

			self.root_node = socket.gethostname()
			self.root_host = socket.gethostbyname(self.root_node)

		else:
			# TODO can we do this scheduler agnostic?
			
			# fill local ranks
			self.local_ranks = [int(gid) for gid in os.environ['SLURM_GTIDS'].split(',')]
			self.local_rank_count = len(self.local_ranks)
			
			command = ['scontrol']
			command.append('show')
			command.append('hostnames')
			command.append(os.environ['SLURM_JOB_NODELIST'])

			process = subprocess.Popen(command, stdout=subprocess.PIPE)
			stdout, stderr = process.communicate()

			self.global_nodes = stdout.splitlines()
			self.global_node_count = len(self.global_nodes)

			self.root_node = self.global_nodes[0] 
			self.root_host = socket.gethostbyname(self.root_node)

	def lookup_rank(self):
		if os.environ['EXAMPI_ENV'] == 'local':
			return self.root_node
		
		else:
			raise NotImplementedError

	def launch(self):
		while not self.shutdown:
			# receive 64B message
			data, addr = self.sock.recvfrom(64)	
			data = data.decode('utf-8').replace('\0','')
			msg = data.split()[0]

			logging.info('received ' + str(msg) + ' from ' + str(addr))

			# process message
			if   msg == 'barrier':
				# local process is at barrier
				self.process_barrier(data)

			elif msg == 'termination':
				# local process died
				self.process_termination(data, addr)

			elif msg == 'global_barrier':
				# node wide barrier request
				self.process_global_barrier(data)

			elif msg == 'global_release':
				# root head node received all global barriers
				self.process_global_release()
			
			elif msg == 'global_error':
				# a process somewhere else died
				self.process_global_error(data)

			else:
				logging.error('head daemon: unrecognized protocol message ' + str(data))
				raise ValueError

	def process_barrier(self, data):
		msg, rank, pid = data.split()
		logging.info('head daemon: barrier ' + str(msg)+ ' ' + str(rank) + ' ' + str(pid))

		# register rank for barrier 
		self.rank_waiting_set.add(rank)
		
		# check if all local ranks are waiting
		if self.barrier_unannounced and len(self.rank_waiting_set) == self.local_rank_count:
			logging.info('head daemon sending global barrier to root')

			self.barrier_unannounced = False

			msg = ('global_barrier '+socket.gethostname()+'\0').ljust(64).encode('utf-8')

			self.sock.sendto(msg, (self.root_node, self.daemon_port)) 

	def process_termination(self, data, addr):
		msg, rank, errorcode = data.split()
		logging.info('head daemon: ' + msg + ' ' + str(rank) + ' ' + str(errorcode))

		# check error code
		if int(errorcode) == 0:
			self.rank_done_set.add(rank)

		# exit once all local have completed
		if len(self.rank_done_set) == self.local_rank_count:
			# todo send global shutdown request
			logging.info('head daemon: completed all local ranks ' + socket.gethostname())
			self.shutdown = True
		
	def process_rank_lookup(self):
		# todo local rank is asking for remote address
		if os.environ['EXAMPI_ENV'] == 'local':
			return socket.gethostname()

		else:
			raise NotImplementedError

	def process_global_barrier(self, data):
		msg, nodename = data.split()
		logging.info('head daemon: ' + str(msg) + ' ' + str(nodename))

		# register, if all, then send release messages
		self.node_waiting_set.add(nodename.replace('\0',''))
		logging.info('present nodes ' + str(self.node_waiting_set))

		logging.info('checking ' + str(len(self.node_waiting_set)) + ' == ' + str(self.global_node_count))
		if len(self.node_waiting_set) == self.global_node_count:
			logging.info('sending global release')
			# send node release messages
			for node in self.node_waiting_set:
				msg = 'global_release\0'.ljust(64).encode('utf-8')
				
				host = socket.gethostbyname(node)
				logging.info('send global release to ' + host + ' ' + node)
				self.sock.sendto(msg, (host, self.daemon_port))
	
	def process_global_release(self):
		logging.info('head daemon: global release')

		# forward release to all ranks
		logging.info('present ranks ' + str(self.rank_waiting_set))
		for rank in self.rank_waiting_set:
			msg = 'release\0'.ljust(64).encode('utf-8')

			# todo local port should use local id instead of global id
			host = socket.gethostbyname(socket.gethostname())
			self.sock.sendto(msg, (host, self.mpi_base_port + int(rank)))
			logging.info('sent release to ' + str(rank))

	def process_global_error(self, data):
		# TODO inform all ranks of error
		raise NotImplementedError 

if __name__ == '__main__':
	# todo read from environment
	daemon_port = int(os.environ["EXAMPI_DAEMON_PORT"])
	mpi_base_port = int(os.environ["EXAMPI_MPI_BASE_PORT"])

	#
	daemon = HeadDaemon(daemon_port, mpi_base_port)
	daemon.launch()
