#! /usr/bin/env python2

import sys, os, re, argparse, subprocess, time, signal, socket

schedulers = ['local', 'slurm', 'osg', 'sge']

MPI_SUCCESS = 0

def local_cleanup():
	for path in os.listdir('.'):
		if path[-3:] == "tmp":
			os.remove(path)

def run_local(arguments):
	numproc = arguments.n
	program = arguments.program

	# TODO check if executable exists
	
	local_cleanup()

	# start numproc processes of program

	# open socket on loopback network as server
	udp_ip = "127.0.0.1"
	udp_port = 50000

	udp_daemon_port = 40000
	udp_comm = 20000

	sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
	sock.bind((udp_ip, udp_port))
	sock.setblocking(0)

	# generate config string
	configstr = 'ppid:' + str(os.getpid()) + '\n'
	configstr += 'size:' + str(numproc) + '\n'
	
	for rank in xrange(numproc):
		# all processes are local
		configstr += str(rank) + ':' + '127.0.0.1:' + str(udp_daemon_port + rank) + ':' + str(udp_comm + rank) + '\n'

	print('Configfile contents:')
	print(configstr)

	# launch children
	processes = {}
	outputs = {}
	for rank in xrange(numproc):
		# seperate binary
		child = [program[0], 'exampilauncher']

		# setup config
		configname = 'mpi.%i.config.tmp' % rank
		with open(configname, 'w') as configfile:
			configfile.write(configstr)

		child.append(configname)
		child.append(str(rank))
		# TODO use global config file

		# setup epoch
		epochname = 'mpi.%i.epoch.tmp' % rank
		epoch = 0

		child.append(epochname)
		child.append(str(epoch))

		with open(epochname, 'w') as epochfile:
			epochfile.write(str(epoch))

		# append user arguments
		child.extend(program[1:])

		print(child)

		# TODO pass environment?
		
		# create file handles
		outname = 'mpi.%i.%i.out' % (os.getpid(), rank)
		errname = 'mpi.%i.%i.err' % (os.getpid(), rank)
		ohandle = open(outname, 'w')
		ehandle = open(errname, 'w')
		outputs[rank] = (ohandle, ehandle)

		process = subprocess.Popen(child, stdout=ohandle, stderr=ehandle)
		processes[rank] = process

	# monitor processes
	processes_barrier = 0
	processes_running = len(processes)
	while processes_running > 0:
		# wait time between processes
		time.sleep(0.1)

		# check socket
		try:
			data = sock.recv(64)
			
			msg, rank, pid = data.split()

			# process global barrier
			if msg == 'barrier':
				processes_barrier += 1

				# is barrier complete?
				if processes_barrier == len(processes):
					for rank in xrange(numproc):
						msg = 'release\0';
						msg = msg.encode('utf-8')
						sock.sendto(msg, (udp_ip, 40000+rank))

		except:
			pass

		# check process alive
		for rank, process in processes.iteritems():
			# check if process is dead
			if process.poll() is not None:
				if process.returncode is MPI_SUCCESS:
					# MPI exited cleanly
					processes_running -= 1

				elif process.returncode is 255:
					# MPI abort called
					pass
				#elif
					# another option? 
	
	# clean up config & epoch files
	sock.close()
	
	for rank in xrange(numproc):
		(ohandle, ehandle) = outputs[rank]

		ohandle.close()
		ehandle.close()

	if not arguments.d:
		local_cleanup();


def run_slurm():
	# TODO execute srun externally, plugin required
	print("SLURM NOT IMPLEMENTED, THIS IS A STUB")
	
def run_sge():
	# TODO
	print("SGE/OSG NOT IMPLEMENTED, THIS IS A STUB")
	print("WE DON'T WANT THIS, SWITCH TO SLURM")

if __name__ == '__main__':
	# command line argument parsing
	parser = argparse.ArgumentParser(description="ExaMPI Process Initiator")

	parser.add_argument('-n', metavar='<numprocs>', type=int, required=True, help='Number of processes to start (required).')

	parser.add_argument('-s', default=schedulers[0], metavar='<scheduler>', type=str, help='Job scheduler environment to use.', choices=schedulers)
	
	parser.add_argument('-d', default=False, metavar='<dirty>', type=str, help='Do not temporary files after execution.')
	
	parser.add_argument('program', metavar='<program>', type=str, nargs=argparse.REMAINDER, help='Program binary to execute with flags.')
	

	# TODO add additional argument possible by standard, section 8.8
	
	arguments = parser.parse_args()
	
	# switch between local, slurm and osg
	if arguments.s is schedulers[0]:
		# local scheduler ie run locally multiple processes
		run_local(arguments)
	
	elif arguments.s is scheduler[1]:
		# use SLURM
		run_slurm()

	elif arguments.s is scheduler[2] or arguments.s is scheduler[3]:
		# use SGE or OSG
		run_sge()
